{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To allow importing of packages in two directories up\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "# Importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from tqdm.auto import tqdm\n",
    "import scipy.stats as sc\n",
    "\n",
    "import io\n",
    "import requests\n",
    "\n",
    "#from core.wca import wca_mean\n",
    "np.random.seed(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_HousingData():\n",
    "    \"\"\"\n",
    "        Function to read boston housing data. \n",
    "    \"\"\"\n",
    "    from sklearn.datasets import load_boston\n",
    "    boston_dataset = load_boston()\n",
    "    df = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)\n",
    "    df['target']=boston_dataset.target\n",
    "    y=df['target']\n",
    "    X=df.drop('target',axis=1)\n",
    "    return (X,y,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the number of clusters\n",
    "k=2\n",
    "\n",
    "# Number of columns to show\n",
    "col_num = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b608311af7847f798ac34d2e8f6e575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iterations: ', max=202, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X, y, df= read_HousingData() \n",
    "\n",
    "# Splitting training and testing data\n",
    "X, X_test, y, y_test = train_test_split(X,y,train_size=0.8,random_state=21)\n",
    "X.reset_index(drop=True,inplace=True)\n",
    "X_test.reset_index(drop=True,inplace=True)\n",
    "y.reset_index(drop=True,inplace=True)\n",
    "y_test.reset_index(drop=True,inplace=True)\n",
    "\n",
    "# Scaling data\n",
    "ss = StandardScaler()\n",
    "cols = X.columns\n",
    "X = ss.fit_transform(X)\n",
    "X = pd.DataFrame(data=X,columns=cols)\n",
    "X_test = ss.transform(X_test)\n",
    "X_test = pd.DataFrame(data=X_test, columns=cols)\n",
    "y = pd.Series(ss.fit_transform(y.values.reshape(-1,1)).reshape(-1))\n",
    "y_test = pd.Series(ss.transform(y_test.values.reshape(-1,1)).reshape(-1))\n",
    "\n",
    "C_random = dict()\n",
    "y_random = dict()\n",
    "for cluster in range(k):\n",
    "    C_random[cluster] = pd.DataFrame(X[:1])\n",
    "    y_random[cluster] = y[:1]\n",
    "\n",
    "# Initializing the p-values\n",
    "pval_random = dict()\n",
    "for cluster in range(k):\n",
    "    pval_random[cluster] = dict()\n",
    "    for i in C_random[0].columns:\n",
    "        pval_random[cluster][i] = list()\n",
    "\n",
    "# Initializing the R2 scores and rmse for cluster 0\n",
    "r2_random = list()\n",
    "rmse_random = list()\n",
    "\n",
    "for i in tqdm(range(int(len(X)/k)), desc = \"Iterations: \"):\n",
    "    for cluster in range(k):\n",
    "        idx = np.random.randint(low=0,high=len(X))\n",
    "        \n",
    "        # For data\n",
    "        C_random[cluster] = C_random[cluster].append(X.iloc[idx])\n",
    "        X.drop(idx, inplace=True)\n",
    "        X.reset_index(drop=True,inplace=True)\n",
    "        C_random[cluster].reset_index(drop=True,inplace=True)\n",
    "        \n",
    "        # For target\n",
    "        y_random[cluster] = y_random[cluster].append(pd.Series(y.iloc[idx]))\n",
    "        y.drop(idx, inplace=True)\n",
    "        y.reset_index(drop=True,inplace=True)\n",
    "        y_random[cluster].reset_index(drop=True,inplace=True)\n",
    "        \n",
    "        \n",
    "        lr = LinearRegression()\n",
    "        lr.fit(C_random[0],y_random[0])\n",
    "        r2_random.append(lr.score(X_test,y_test))\n",
    "        \n",
    "        y_pred = lr.predict(X_test)\n",
    "        rmse_random.append(mean_squared_error(y_pred=y_pred,y_true=y_test)**(1/2))\n",
    "        # For p_value\n",
    "        for i in C_random[0].columns:\n",
    "            pval_random[cluster][i].append(sc.ks_2samp(C_random[cluster][i],df.drop('target',axis=1)[i])[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1caacab0e80a4a638857f12183499e52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iterations: ', max=201, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Getting the data\n",
    "X, y, df= read_HousingData() \n",
    "X, X_test, y, y_test = train_test_split(X,y,train_size=0.8,random_state=21)\n",
    "X.reset_index(drop=True,inplace=True)\n",
    "X_test.reset_index(drop=True,inplace=True)\n",
    "y.reset_index(drop=True,inplace=True)\n",
    "y_test.reset_index(drop=True,inplace=True)\n",
    "\n",
    "# Scaling data\n",
    "ss = StandardScaler()\n",
    "cols = X.columns\n",
    "X = ss.fit_transform(X)\n",
    "X = pd.DataFrame(data=X,columns=cols)\n",
    "X_test = ss.transform(X_test)\n",
    "X_test = pd.DataFrame(data=X_test, columns=cols)\n",
    "y = pd.Series(ss.fit_transform(y.values.reshape(-1,1)).reshape(-1))\n",
    "y_test = pd.Series(ss.transform(y_test.values.reshape(-1,1)).reshape(-1))\n",
    "\n",
    "def sum_of_points(data,df_cluster):\n",
    "    \"\"\"\n",
    "        calculates the distance of a point (data) from each point of cluster and sums it up\n",
    "    \"\"\"\n",
    "    sum_of_points=0\n",
    "    for data2, index in df_cluster.iterrows():\n",
    "        sum_of_points=sum_of_points+np.linalg.norm(np.asarray(data2)- np.asarray(data))\n",
    "    return sum_of_points\n",
    "\n",
    "\n",
    "def wca_mean(X, X_test, y, y_test, k, df):\n",
    "    \"\"\"\n",
    "        Implementes the WCA algorithm which maximizes the entropy with respect to the mean of the clusters\n",
    "\n",
    "        X = Dataframe\n",
    "        k = number of clusters\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    # Intializing the clusters\n",
    "    C = dict()\n",
    "    y_random = dict()\n",
    "    for cluster in range(k):\n",
    "        C[cluster] = pd.DataFrame()\n",
    "\n",
    "    # Initializing the R2 scores and rmse for cluster 0\n",
    "    r2 = list()\n",
    "    rmse = list()\n",
    "    # Calculating the mean vector\n",
    "    mean_vector = X.mean()\n",
    "\n",
    "    # Choosing the seed points based on the minimum distance from the mean vector\n",
    "    X['dist_mean'] = X.apply(lambda x: np.linalg.norm(np.asarray(x)- np.asarray(mean_vector)), axis=1)\n",
    "    dist_means = X.sort_values(by='dist_mean')\n",
    "    \n",
    "    # Dropping the the datapoints which have already been assigned as seed\n",
    "    idx_to_drop = dist_means.index[:k]\n",
    "    dist_means.reset_index(drop=True,inplace=True)\n",
    "    X.drop('dist_mean',axis=1,inplace=True)\n",
    "    X.drop(idx_to_drop, inplace=True)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Assigning seed points to the clusters\n",
    "    mu = list()\n",
    "    for cluster in range(k):\n",
    "        C[cluster] = C[cluster].append(dist_means.iloc[cluster].drop('dist_mean'))\n",
    "        y_random[cluster] = pd.Series(y[idx_to_drop[cluster]])\n",
    "        mu.append(C[cluster].mean())\n",
    "        \n",
    "    y.drop(idx_to_drop, inplace=True)\n",
    "    \n",
    "    # Running the algorithm\t\n",
    "    \n",
    "    # Initializing the p-value list which would be used for plotting\n",
    "    pval = dict()\n",
    "\n",
    "    for cluster in range(k):\n",
    "        pval[cluster] = dict()\n",
    "        for i in C[0].columns:\n",
    "            pval[cluster][i] = list()\n",
    "\n",
    "    # Algorithm\n",
    "    for i in tqdm(range(int(len(X)/k)), desc='Iterations: '):\n",
    "        for cluster in range(k):\n",
    "            \n",
    "            # Calculating the distances from the all the points of each cluster (in Descending order)\n",
    "            X['dist_mean'] = X.apply(lambda x: sum_of_points(x,C[cluster]),axis=1)\n",
    "            dist_means = X.sort_values(by='dist_mean', ascending=False)\n",
    "            idx_to_drop = dist_means.index[0]\n",
    "            dist_means.reset_index(drop=True,inplace=True)\n",
    "            X.drop('dist_mean',axis=1,inplace=True)\n",
    "\n",
    "            # Assigning the top value to the cluster\n",
    "            C[cluster] = C[cluster].append(dist_means.iloc[0].drop('dist_mean'))\n",
    "            C[cluster] = C[cluster].reset_index(drop=True)\n",
    "            \n",
    "            # Updating means of each cluster\n",
    "            mu[cluster] = C[cluster].mean()\n",
    "            \n",
    "            # Remove datapoint from X?\n",
    "            X.drop(idx_to_drop,inplace=True)\n",
    "            X.reset_index(drop=True,inplace=True)\n",
    "            \n",
    "            # For target\n",
    "            y_random[cluster] = y_random[cluster].append(pd.Series(y.iloc[idx_to_drop]))\n",
    "            y.drop(idx_to_drop, inplace=True)\n",
    "            y.reset_index(drop=True,inplace=True)\n",
    "            y_random[cluster].reset_index(drop=True,inplace=True)\n",
    "\n",
    "\n",
    "            lr = LinearRegression()\n",
    "            lr.fit(C[0],y_random[0])\n",
    "            r2.append(lr.score(X_test,y_test))\n",
    "\n",
    "            y_pred = lr.predict(X_test)\n",
    "            rmse.append(mean_squared_error(y_pred=y_pred,y_true=y_test)**(1/2))\n",
    "\n",
    "            for i in C[0].columns:\n",
    "                pval[cluster][i].append(sc.ks_2samp(C[cluster][i],df.drop('target',axis=1)[i])[1])\n",
    "\n",
    "    return(C, pval, rmse, r2)\n",
    "\n",
    "\n",
    "\n",
    "# Running the wca_mean function\n",
    "C, pval, rmse, r2 = wca_mean(X, X_test, y, y_test, k, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rmse_random)\n",
    "plt.title(\"Random Sampling\")\n",
    "plt.xlabel(\"# of Samples\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(rmse)\n",
    "plt.title(\"WCA Mean Sampling\")\n",
    "plt.xlabel(\"# of Samples\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
